---
title: "project"
author: "Menghan Han"
date: "2020/5/24"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## General Ideas

For the dataset, I splitted the training data into training set and validation set. I biult several models with different methods and applied the models in the validation set. I selected the model with the highest accuracy and then used it to predict the 20 cases in the testing data. For preprocess, I used 'nearZeroVar' to remove zero convariate and PCA method to select the classifiers that are most important.

## Library
```{r}
library(lattice)
library(ggplot2)
library(caret)
library(e1071)
library(kernlab)
library(AppliedPredictiveModeling)
library(gbm)
library(RANN)
library(dplyr)
```


## Data Extraction

Before running the following codes, please make sure the two datasets are in the working directory.
```{r}
training <- read.csv('pml-training.csv',header = TRUE)
testing <- read.csv('pml-testing.csv',header = TRUE)
```

## Data Cleaning

I used 'nearZeroVar' to remove zero convariate, and then I omitted the NA and information that is unrelated with activity recognition such as participants' name and time.
```{r}
nsv <- nearZeroVar(training, saveMetrics = TRUE)  #etect zero convariates
training <- training[,which(nsv$nzv=='FALSE')] #remove zero convariates for training data
testing <- testing[,which(nsv$nzv=='FALSE')]   #remove zero convariates for testing data
training<- training[,-c(1,2,3,4,5,6)]  #omit useless info
testing<- testing[,-c(1,2,3,4,5,6)]    #omit useless info
testing <- data.frame(t(na.omit(t(testing))))   #omit NA
training <- data.frame(t(na.omit(t(training)))) #omit NA
```

## Data Split

I splitted the training data into training set(70%) and validation set(30%).
```{r}
intrain <- createDataPartition(y=training$classe,p=0.7,list=FALSE)
train <- training[intrain,]
validation <- training[-intrain,]
for (i in c(1:52)){                               #change the *class* from factor to numeric
  train[,i]<-as.numeric(as.character(train[,i]))
}
for (i in c(1:52)){                               #change the class from factor to numeric
  validation[,i]<-as.numeric(as.character(validation[,i]))
}
validation[53]<-as.factor(validation[,53])       #change the class of variable *class* to facor
```

## Preprocess -- PCA

There are 52 variables left after eliminating useless data. Thus, I used PCA method to reduce the number of variables. As a result, I got 12 dimensions that gather the most information.
```{r}
prepro <- preProcess(train[,-53],method='pca',pcaComp = 12)  #pca method
trainpc <- predict(prepro,train)
```

## Model Biulding

I biult 3 models with different method:for model 1, I used rpart method; for model2, I used gbm method; for model 3, I combined the predictors in model 1 and model 2.
```{r}
mod1 <- train(classe ~ .,method='rpart',data=trainpc)             #model 1
mod2 <- train(classe ~ .,method='gbm',data=trainpc,verbose=FALSE) #model 2

valid1 <- predict(prepro,validation)
valid2 <- predict(prepro,validation)

trainc <- data.frame(valid1,valid2,classe=validation$classe)
combmodfit <- train(classe ~.,method='gam',data=trainc)           #model 3
valid3 <- predict(combmodfit,trainc)
trainc[,1]<-as.factor(trainc[,1])
```

## Model Selection

I selected the best model by using validation set. Model 2 has the highest accuracy 0.75. 
```{r}
confusionMatrix(validation$classe,predict(mod1,valid1))
confusionMatrix(validation$classe,predict(mod2,valid2))
confusionMatrix(trainc$classe,valid3)
```

## Results

Model 2 with gbm method is used to predict the 20 test cases.
```{r}
test <- predict(prepro,testing)
predictions <- predict(mod2,newdata=test)
print(predictions)
```


